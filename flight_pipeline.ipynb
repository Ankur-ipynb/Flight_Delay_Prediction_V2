{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64055580-39c1-4164-b8c0-3b5533d18138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "db_path = \"D:/flight_db/flight_predictions.db\"\n",
    "if os.path.exists(db_path):\n",
    "    print(f\"Database exists at {db_path}\")\n",
    "else:\n",
    "    print(f\"Database not found at {db_path}, creating new\")\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS predictions\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE predictions (\n",
    "        flight_number TEXT,\n",
    "        scheduled_departure TEXT,\n",
    "        delay_minutes INTEGER,\n",
    "        is_delayed INTEGER,\n",
    "        predicted_delayed REAL,\n",
    "        temperature REAL,\n",
    "        departure_airport TEXT\n",
    "    )\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# Verify schema\n",
    "cursor.execute(\"PRAGMA table_info(predictions)\")\n",
    "schema = cursor.fetchall()\n",
    "print(\"Table schema:\")\n",
    "for col in schema:\n",
    "    print(col)\n",
    "\n",
    "conn.close()\n",
    "print(\"Table recreated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5d6d8-05f2-49eb-9fcf-66e7ba0f2a85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"D:\\\\python39venv\\\\Scripts\\\\python.exe\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"D:\\\\python39venv\\\\Scripts\\\\python.exe\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"D:\\\\hadoop-3.3.6\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "from pyspark.ml import PipelineModel\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# SparkSession for model loading\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FlightDelayStreaming\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.5\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"file:///\") \\\n",
    "    .config(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.LocalFileSystem\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark version:\", spark.version)\n",
    "print(\"Hadoop home:\", os.environ.get(\"HADOOP_HOME\"))\n",
    "\n",
    "try:\n",
    "    model = PipelineModel.load(\"D:/flight_delay_model\")\n",
    "    print(\"Model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading model:\", str(e))\n",
    "    spark.stop()\n",
    "    raise e\n",
    "\n",
    "spark.stop()\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FlightDelayStreaming\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.5\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"file:///\") \\\n",
    "    .config(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.RawLocalFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.file.impl.disable.cache\", \"true\") \\\n",
    "    .config(\"spark.hadoop.hadoop.io.native.lib.available\", \"false\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "try:\n",
    "    kafka_df = spark.readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "        .option(\"subscribe\", \"flight-data\") \\\n",
    "        .option(\"startingOffsets\", \"latest\") \\\n",
    "        .load()\n",
    "    print(\"Connected to Kafka\")\n",
    "except Exception as e:\n",
    "    print(\"Kafka connection error:\", str(e))\n",
    "    spark.stop()\n",
    "    raise e\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"flight_number\", StringType()),\n",
    "    StructField(\"departure_airport\", StringType()),\n",
    "    StructField(\"arrival_airport\", StringType()),\n",
    "    StructField(\"scheduled_departure\", StringType()),\n",
    "    StructField(\"temperature\", DoubleType()),\n",
    "    StructField(\"wind_speed\", DoubleType()),\n",
    "    StructField(\"precipitation\", DoubleType()),\n",
    "    StructField(\"delay_minutes\", IntegerType())\n",
    "])\n",
    "flight_df = kafka_df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(col(\"value\"), schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")\n",
    "\n",
    "flight_df = flight_df.withColumn(\"is_delayed\", when(col(\"delay_minutes\") > 15, 1).otherwise(0))\n",
    "\n",
    "pred_df = model.transform(flight_df)\n",
    "\n",
    "output_df = pred_df.select(\n",
    "    col(\"flight_number\"),\n",
    "    col(\"scheduled_departure\"),\n",
    "    col(\"delay_minutes\"),\n",
    "    col(\"is_delayed\"),\n",
    "    col(\"prediction\").alias(\"predicted_delayed\"),\n",
    "    col(\"temperature\"),\n",
    "    col(\"departure_airport\")\n",
    ")\n",
    "\n",
    "output_df.printSchema()\n",
    "\n",
    "console_query = output_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "def write_to_sqlite(batch_df, batch_id):\n",
    "    try:\n",
    "        pandas_df = batch_df.toPandas()\n",
    "        print(f\"Batch {batch_id}: {len(pandas_df)} rows to save\")\n",
    "        if not pandas_df.empty:\n",
    "            conn = sqlite3.connect(\"D:/flight_db/flight_predictions.db\")\n",
    "            pandas_df.to_sql(\"predictions\", conn, if_exists=\"append\", index=False)\n",
    "            conn.commit()\n",
    "            print(f\"Batch {batch_id}: Saved {len(pandas_df)} rows to SQLite\")\n",
    "            conn.close()\n",
    "        else:\n",
    "            print(f\"Batch {batch_id}: No data to save\")\n",
    "    except Exception as e:\n",
    "        print(f\"Batch {batch_id}: SQLite error: {str(e)}\")\n",
    "\n",
    "sqlite_query = output_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .foreachBatch(write_to_sqlite) \\\n",
    "    .start()\n",
    "\n",
    "def plot_batch(batch_df, batch_id):\n",
    "    pandas_df = batch_df.toPandas()\n",
    "    if not pandas_df.empty:\n",
    "        fig = px.scatter(\n",
    "            pandas_df,\n",
    "            x=\"scheduled_departure\",\n",
    "            y=\"delay_minutes\",\n",
    "            color=\"predicted_delayed\",\n",
    "            size=\"temperature\",\n",
    "            title=\"Flight Delays: Predicted vs Actual\",\n",
    "            labels={\n",
    "                \"scheduled_departure\": \"Time\",\n",
    "                \"delay_minutes\": \"Delay (min)\",\n",
    "                \"predicted_delayed\": \"Predicted Delayed\",\n",
    "                \"temperature\": \"Temp (Â°C)\"\n",
    "            },\n",
    "            hover_data=[\"flight_number\", \"departure_airport\"]\n",
    "        )\n",
    "        fig.update_traces(marker=dict(sizemode='area', sizemin=5))\n",
    "        fig.show()\n",
    "\n",
    "plot_query = output_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"flight_predictions\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .foreachBatch(plot_batch) \\\n",
    "    .start()\n",
    "\n",
    "def alert_delayed(batch_df, batch_id):\n",
    "    delayed = batch_df.filter(col(\"predicted_delayed\") == 1.0).toPandas()\n",
    "    if not delayed.empty:\n",
    "        print(\"Delayed flights:\\n\", delayed[[\"flight_number\", \"delay_minutes\", \"scheduled_departure\"]].to_string(index=False))\n",
    "\n",
    "alert_query = output_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .foreachBatch(alert_delayed) \\\n",
    "    .start()\n",
    "\n",
    "try:\n",
    "    alert_query.awaitTermination(timeout=180)\n",
    "except KeyboardInterrupt:\n",
    "    console_query.stop()\n",
    "    sqlite_query.stop()\n",
    "    plot_query.stop()\n",
    "    alert_query.stop()\n",
    "    spark.stop()\n",
    "    print(\"Streaming stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374def66-4f9b-4626-872f-01e554b87f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delays by Airport:\n",
      "AYD: 31/129 (24.03%)\n",
      "HYD: 32/116 (27.59%)\n",
      "IXD: 21/118 (17.80%)\n",
      "JFK: 2/2 (100.00%)\n",
      "VNS: 33/141 (23.40%)\n",
      "Average delay (delayed flights): 38.11 minutes\n"
     ]
    }
   ],
   "source": [
    "#avg flight delay\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"D:/flight_db/flight_predictions.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT departure_airport, \n",
    "           COUNT(*) as total, \n",
    "           SUM(CASE WHEN is_delayed = 1 THEN 1 ELSE 0 END) as delayed\n",
    "    FROM predictions \n",
    "    GROUP BY departure_airport\n",
    "\"\"\")\n",
    "print(\"Delays by Airport:\")\n",
    "for row in cursor.fetchall():\n",
    "    airport, total, delayed = row\n",
    "    print(f\"{airport}: {delayed}/{total} ({delayed/total:.2%})\")\n",
    "\n",
    "cursor.execute(\"SELECT AVG(delay_minutes) FROM predictions WHERE is_delayed = 1\")\n",
    "avg_delay = cursor.fetchone()[0] or 0\n",
    "print(f\"Average delay (delayed flights): {avg_delay:.2f} minutes\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50bb679b-3137-4ab9-bc31-b7b856efb331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.70% (378/506 correct)\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"D:/flight_db/flight_predictions.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT COUNT(*) FROM predictions WHERE is_delayed = predicted_delayed\")\n",
    "correct = cursor.fetchone()[0]\n",
    "cursor.execute(\"SELECT COUNT(*) FROM predictions\")\n",
    "total = cursor.fetchone()[0]\n",
    "\n",
    "accuracy = correct / total if total > 0 else 0\n",
    "print(f\"Accuracy: {accuracy:.2%} ({correct}/{total} correct)\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f41db7-a952-42f7-8a26-38e9ce436a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
